{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tkinter import messagebox\n",
        "from tkinter import *\n",
        "from tkinter import simpledialog\n",
        "import tkinter\n",
        "from tkinter import filedialog\n",
        "from tkinter.filedialog import askopenfilename\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "labels = ['0', '1']\n",
        "## 0== NO (emp not promoted)\n",
        "## 1 == Yes (emp is promoted)\n",
        "fucntion to upload dataset\n",
        " def uploadDataset():\n",
        "  global filename, dataset\n",
        "  text.delete('1.0', END)\n",
        "  filename = filedialog.askopenfilename(initialdir=\"Dataset\") #upload dataset file\n",
        "  text.insert(END,filename+\" loaded\\n\\n\")\n",
        "  dataset = pd.read_csv(filename) #read dataset from uploaded file\n",
        "  text.insert(END,\"Dataset Values\\n\\n\")\n",
        "  text.insert(END,str(dataset.head()\n",
        " def preprocessing():\n",
        "  text.delete('1.0', END)\n",
        "  global dataset, scaler, le\n",
        "  global X_train, X_test, y_train, y_test, X, Y, sc, col\n",
        "   # Replace missing values with 0\n",
        "   dataset.fillna(0, inplace=True)\n",
        "  # Convert categorical columns to strings before encoding\n",
        "   categorical_columns = ['department', 'education', 'gender', 'recruitment_channel', 'region']\n",
        "\n",
        "def preprocessing():\n",
        "  text.delete('1.0', END)\n",
        "  global dataset, scaler, le\n",
        "  global X_train, X_test, y_train, y_test, X, Y, sc, col\n",
        " # Replace missing values with 0\n",
        "  dataset.fillna(0, inplace=True)\n",
        "  # Convert categorical columns to strings before encoding\n",
        "  categorical_columns = ['department', 'education', 'gender', 'recruitment_channel', 'region']\n",
        "  for col in categorical_columns:\n",
        "  dataset[col] = dataset[col].astype(str)  # Convert to string\n",
        "  le = LabelEncoder()\n",
        "  dataset[col] = le.fit_transform(dataset[col])\n",
        "   # Selecting features and target\n",
        "   X = dataset.iloc[:, 1:12]\n",
        "   Y = dataset.iloc[:, -1]\n",
        "   text.insert(END, \"Dataset after features normalization\\n\\n\")\n",
        "   text.insert(END, str(X) + \"\\n\\n\")\n",
        "   text.insert(END, \"Total records found in dataset : \" + str(X.shape[0]) + \"\\n\")\n",
        "   text.insert(END, \"Total features found in dataset: \" + str(X.shape[1]) + \"\\n\\n\")\n",
        "  def Smote_tech():\n",
        "  global X_train, y_train,X_test,y_test\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,    random_state=42)\n",
        "  smote = SMOTE(random_state=42)\n",
        "  X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "  text.insert(END, \"\\nAfter Applying SMOTE Technique:\\n\")\n",
        "  text.insert(END, \"Resampled Training Data Shape: \" + str(X_train.shape)\n",
        "   text.insert(END, \"Resampled Training Target Distribution:\\n\")\n",
        "    text.insert(END, str(y_train.value_counts()) + \"\\n\")\n",
        " # Split dataset into train and test sets\n",
        "text.insert(END, \"Dataset Train and Test Split\\n\\n\")\n",
        "text.insert(END, \"80% dataset records : \" + str(X_train.shape[0]) + \"\\n\")\n",
        " text.insert(END, \"20% dataset records : \" + str(X_test.shape[0]) + \"\\n\")\n",
        "def histogram_plot(df, column):\n",
        " \"\"\"Histogram for a numerical column.\"\"\"??L:\n",
        " plt.figure(figsize=(8, 5))\n",
        " sns.histplot(df[column], bins=30, kde=True)\n",
        "  plt.title(f'Histogram of {column}')\n",
        "  plt.xlabel(column)\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.show()\n",
        "def box_plot(df, column):\n",
        "   \"\"\"Box plot for a numerical column.\"\"\"\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  sns.boxplot(x=df[column])\n",
        "  plt.title(f'Box Plot of {column}')\n",
        "  plt.xlabel(column) plt.show()\n",
        "\"\"\"Scatter plot between two numerical columns.\"\"\"\n",
        " plt.figure(figsize=(8, 5))\n",
        "  sns.scatterplot(x=df[x_col], y=df[y_col])\n",
        "  plt.title(f'Scatter Plot of {x_col} vs {y_col}')\n",
        "  plt.xlabel(x_col)\n",
        "  plt.ylabel(y_col)\n",
        "  plt.show()\n",
        "  def correlation_heatmap(df):\n",
        "  \"\"\"Heatmap of correlation matrix for numerical columns.\"\"\"\n",
        " plt.figure(figsize=(10, 6))\n",
        " sns.heatmap(df.corr(), annot=True, cmap='coolwarm',       fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "def violin_plot(df, column):\n",
        "\"\"\"Violin plot for a numerical column.\"\"\"\n",
        " plt.figure(figsize=(8, 5))\n",
        " sns.violinplot(x=df[column])\n",
        " plt.title(f'Violin Plot of {column}')\n",
        " plt.xlabel(column)\n",
        " plt.show()\n",
        " def count_plot(df, column):\n",
        " \"\"\"Count plot for a categorical column.\"\"\"\n",
        " plt.figure(figsize=(8, 5))\n",
        " sns.countplot(x=df[column])\n",
        " plt.title(f'Count Plot of {column}')\n",
        " plt.xlabel(column)\n",
        " plt.ylabel('Count')\n",
        " plt.show()\n",
        " def kde_plot(df, column):\n",
        " \"\"\"Kernel Density Estimate (KDE) plot for a numerical\n",
        "column.\"\"\"\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.kdeplot(df[column], shade=True)\n",
        "plt.title(f'KDE Plot of {column}')\n",
        "plt.xlabel(column)\n",
        "plt.ylabel('Density')\n",
        "plt.show()\n",
        "def EDA():\n",
        "text.delete('1.0', END)\n",
        "global dataset\n",
        "df = dataset\n",
        "histogram_plot(df, \"age\")\n",
        "box_plot(df, \"age\")\n",
        "correlation_heatmap(df)\n",
        "count_plot(df, \"is_promoted\")\n",
        "def calculateMetrics(algorithm, testY, predict):\n",
        "global labels\n",
        " p = precision_score(testY, predict,average='macro') * 100\n",
        "  r = recall_score(testY, predict,average='macro') * 100\n",
        "  f = f1_score(testY, predict,average='macro') * 100\n",
        "  a = accuracy_score(testY,predict)*100\n",
        "  accuracy.append(a)\n",
        "  precision.append(p)\n",
        "  recall.append(r)\n",
        "  fscore.append(f)\n",
        "  text.insert(END,algorithm+\" Accuracy  : \"+str(a)+\"\\n\")\n",
        "  text.insert(END,algorithm+\" Precision : \"+str(p)+\"\\n\")\n",
        "  text.insert(END,algorithm+\" Recall    : \"+str(r)+\"\\n\")\n",
        "  text.insert(END,algorithm+\" FSCORE    : \"+str(f)+\"\\n\\n\")\n",
        "  conf_matrix = confusion_matrix(testY, predict)\n",
        "  ax = sns.heatmap(conf_matrix, xticklabels = labels,\n",
        "yticklabels = labels, annot = True, cmap=\"viridis\" ,fmt    =\"g\");\n",
        " ax.set_ylim([0,len(labels)])\n",
        " plt.title(algorithm+\" Confusion matrix\")\n",
        " plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.show()\n",
        "def run_LRC():\n",
        "text.delete('1.0', END)\n",
        "global X_train, X_test, y_train, y_test, X, Y\n",
        "global accuracy, precision, recall, fscore\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "fscore =\n",
        "# Check if the pkl file exists\n",
        " if os.path.exists('model/LogisticRegression_weights.pkl'):\n",
        " # Load the model from the pkl file\n",
        "  rf_classifier= joblib.load('model/LogisticRegression_weights.pkl')\n",
        "  predict = rf_classifier.predict(X_test)\n",
        "  calculateMetrics(\"LogisticRegression\", predict, y_test)\n",
        "    else:\n",
        "clf = LogisticRegression(\n",
        " penalty='l2',\n",
        " dual=False,\n",
        " tol=0.01,  # Increased tolerance for early stopping\n",
        " C=0.1,  # Stronger regularization (lower C)\n",
        " fit_intercept=True,\n",
        " intercept_scaling=1,\n",
        "  class_weight='balanced',  # Alters class distribution effect\n",
        "  random_state=42,  # Ensures some randomness\n",
        " solver='saga',  # Stochastic Approximation for added randomness\n",
        " max_iter=1,  # Fewer iterations\n",
        " multi_class='ovr',  # One-vs-Rest reduces model expressiveness\n",
        " verbose=0,\n",
        " warm_start=True,  # Continues from previous fits, increasing instability\n",
        "  n_jobs=None,\n",
        "  l1_ratio=None)\n",
        " # Train the classifier on the training data\n",
        " clf.fit(X_train, y_train)\n",
        "  # Make predictions on the test data\n",
        " predict=clf.predict(X_test)\n",
        " api_view(['GET'])\n",
        "def officer_list(request):\n",
        "Officer = officer.objects.select_related('user').all() serializer = officer Serializer(officers, many=True) return Response(serializer.data)\n",
        "'model/LogisticRegression_weights.pkl') print(\"LogisticRegression model trained and model weights saved.\")\n",
        "\n",
        "calculateMetrics(\"Existing LRC\", predict, y_test)\n",
        "def runDecisionTree():\n",
        "global classifier\n",
        "global X_train, X_test, y_train, y_test, X, Y, pca\n",
        "# Check if the pkl file exists\n",
        "if os.path.exists('ada_weights.pkl'):\n",
        "# Load the model from the pkl file\n",
        "classifier= joblib.load('ada_weights.pkl')\n",
        "predict = classifier.predict(X_test)\n",
        "calculateMetrics(\"DTC with AdaBoost Classifier\", predict, y_test)\n",
        "else:\n",
        "# Initialize a DecisionTreeClassifier as the base estimator for AdaBoost\n",
        "base_estimator = DecisionTreeClassifier(max_depth=10)\n",
        "# Initialize the AdaBoost model with chosen parameters\n",
        "classifier= AdaBoostClassifier(base_estimator=base_estimator)\n",
        "# Train the classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "# Make predictions on the test data\n",
        "\n",
        "predict=classifier.predict(X_test)\n",
        " # Save the model weights to a pkl file joblib.dump(classifier, 'ada_weights.pkl')\n",
        "print(\"DT with Adaboost classifier_model trained and model weights saved.\")\n",
        "calculateMetrics(\"DTC with AdaBoost Classifier\", predict, y_test)\n",
        "def Detection():\n",
        "text.delete('1.0', END)\n",
        "global sc,classifier,le,dataset\n",
        "filename = filedialog.askopenfilename(initialdir=\"Dataset\")\n",
        "dataset = pd.read_csv(filename)\n",
        "le=LabelEncoder()\n",
        "dataset['department']=le.fit_transform(dataset['department'])\n",
        "dataset['education']=le.fit_transform(dataset['education'])\n",
        "dataset['gender']=le.fit_transform(dataset['gender'])\n",
        "dataset['recruitment_channel']=le.fit_transform(dataset['recruitment_channel'])\n",
        "dataset['region']=le.fit_transform(dataset['region'])\n",
        "dataset.fillna(0, inplace = True)\n",
        "predict = classifier.predict(dataset)\n",
        "test_temp = pd.read_csv(filename)#read data\n",
        "from uploaded file\n",
        "for index, row in test_temp.iterrows():\n",
        "# Get the prediction for the current row\n",
        "prediction = predict[index]\n",
        "predicted_outcome = labels[predi\n",
        "# Print the current row of the dataset followed by its  predicted outcome\n",
        "text.insert(END, f'Row {index + 1}: {row.to_dict()} - Predicted Outcome:\n",
        "{predicted_outcome}\\n\\n\\n\\n\\n')\n",
        "import tkinter as tk\n",
        "def show_admin_buttons():\n",
        "# Clear ADMIN-related buttons\n",
        "clear_buttons()\n",
        "# Add ADMIN-specific buttons\n",
        " tk.Button(main, text=\"Upload Dataset\",        command=uploadDataset, font=font1).place(x=330, y=550)\n",
        " tk.Button(main, text=\"Preprocess Dataset\", command=preprocessing, font=font1).place(x=500, y=550)\n",
        "tk.Button(main, text=\"EDA\", command=EDA, font=font1).place(x=800, y=550)\n",
        "tk.Button(main, text=\"Smote\", command=Smote_tech, font=font1).place(x=675, y=550)\n",
        "tk.Button(main, text=\"Existing LRC\", command=run_LRC, font=font1).place(x=900, y=550)\n",
        "tk.Button(main, text=\"Proposed DTC with AdaBoost Classifier\", command=runDecisionTree, font=font1).place(x=1050, y=550)\n",
        "# Clear USER-related buttons\n",
        "clear_buttons()\n",
        "# Add USER-specific buttons\n",
        "tk.Button(main, text=\"Prediction From Test Data\",  command=Detection, font=font1).place(x=330, y=650)\n",
        "def clear_buttons():\n",
        "# Remove all buttons except ADMIN and USER\n",
        "for widget in main.winfo_children():\n",
        "if isinstance(widget, tk.Button) and widget not in [admin_button, user_button]:\n",
        " widget.destroy()\n",
        "# Initialize the main tkinter window\n",
        "main = tk.Tk()\n",
        "screen_width = main.winfo_screenwidth()\n",
        "screen_height = main.winfo_screenheight()\n",
        "main.geometry(f\"{screen_width}x{screen_height}\"# Configure title\n",
        "font = ('times', 18, 'bold')\n",
        "title = Label(main, text='Employee Promotion Forecasting with ML')\n",
        "title.config(bg='white', fg='black')\n",
        "title.config(font=font)\n",
        "title.config(height=3, width=120)\n",
        "title.place(x=0,y=5)\n",
        "# ADMIN and USER Buttons (Always visible)\n",
        "font1 = ('times', 12, 'bold')\n",
        "admin_button = tk.Button(main, text=\"ADMIN\", command=show_admin_buttons, font=font1, width=20, height=2, bg='LightBlue')\n",
        "admin_button.place(x=50, y=550)\n",
        "user_button = tk.Button(main, text=\"USER\", command=show_user_buttons, font=font1, width=20, height=2, bg='LightGreen')\n",
        "user_button.place(x=50, y=650)\n",
        "font1 = ('times', 12, 'bold')\n",
        "text=Text(main,height=20,width=180)\n",
        "scroll=Scrollbar(text)\n",
        "text.configure(yscrollcommand=scroll.set)\n",
        "text.place(x=50,y=120)\n",
        "text.config(font=font1)\n",
        "\n"
      ],
      "metadata": {
        "id": "INNNcQWTIjY9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}